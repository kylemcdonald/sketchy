{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is for computing the performance of the network on our sketchy benchmark. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## caffe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import caffe. You'll need to have caffe installed, as well as python interface for caffe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: specify your caffe root folder here\n",
    "# caffe_root = \"X:\\caffe_siggraph/caffe-windows-master\"\n",
    "# sys.path.insert(0, caffe_root+'/python')\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load up the network. You can change the path to your own network here. Make sure to use the matching deploy prototxt files and change the target layer to your layer name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: change to your own network and deploying file\n",
    "PRETRAINED_FILE = '../models/triplet_googlenet/triplet_googlenet_final.caffemodel' \n",
    "sketch_model = '../models/triplet_googlenet/Triplet_googlenet_sketchdeploy.prototxt'\n",
    "image_model = '../models/triplet_googlenet/Triplet_googlenet_imagedeploy.prototxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()\n",
    "#caffe.set_mode_cpu()\n",
    "sketch_net = caffe.Net(sketch_model, PRETRAINED_FILE, caffe.TEST)\n",
    "img_net = caffe.Net(image_model, PRETRAINED_FILE, caffe.TEST)\n",
    "sketch_net.blobs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: set output layer name. You can use sketch_net.blobs.keys() to list all layer\n",
    "output_layer_sketch = 'pool5/7x7_s1_s'\n",
    "output_layer_image = 'pool5/7x7_s1_p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set the transformer\n",
    "transformer = caffe.io.Transformer({'data': np.shape(sketch_net.blobs['data'].data)})\n",
    "transformer.set_mean('data', np.array([104, 117, 123]))\n",
    "transformer.set_transpose('data',(2,0,1))\n",
    "transformer.set_channel_swap('data', (2,1,0))\n",
    "transformer.set_raw_scale('data', 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sketchy test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#photo paths\n",
    "photo_paths = '/home/kyle/256x256/photo/tx_000100000000/'\n",
    "sketch_paths = '/home/kyle/256x256/sketch/tx_000000001010/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load up test images\n",
    "# with open('../list/test_img_list.txt','r') as my_file:\n",
    "#     test_img_list = [c.rstrip() for c in my_file.readlines()]\n",
    "\n",
    "test_img_list = [\n",
    "    'airplane/n02691156_10151.jpg',\n",
    "    'airplane/n02691156_10153.jpg',\n",
    "    'airplane/n02691156_10168.jpg',\n",
    "    'zebra/n02391049_10132.jpg',\n",
    "    'zebra/n02391049_10175.jpg',\n",
    "    'zebra/n02391049_1024.jpg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract feature for all test images\n",
    "feats = []\n",
    "N = np.shape(test_img_list)[0]\n",
    "for i,path in enumerate(test_img_list):\n",
    "    imgname = path.split('/')[-1]\n",
    "    imgname = imgname.split('.jpg')[0]\n",
    "    imgcat = path.split('/')[0]\n",
    "    print('\\r',str(i+1)+'/'+str(N)+ ' '+'Extracting ' +path+'...')\n",
    "    full_path = photo_paths + path\n",
    "    img = (transformer.preprocess('data', caffe.io.load_image(full_path.rstrip())))\n",
    "    img_in = np.reshape([img],np.shape(sketch_net.blobs['data'].data))\n",
    "    out_img = img_net.forward(data=img_in)\n",
    "    out_img = np.copy(out_img[output_layer_image]) \n",
    "    feats.append(out_img)\n",
    "    print('done')\n",
    "np.shape(feats)\n",
    "feats = np.resize(feats,[np.shape(feats)[0],np.shape(feats)[2]])  #quick fixed for size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build nn pool\n",
    "from sklearn.neighbors import NearestNeighbors,LSHForest\n",
    "nbrs  = NearestNeighbors(n_neighbors=np.size(feats,0), algorithm='brute',metric='cosine').fit(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute score\n",
    "\n",
    "num_query = 0\n",
    "count_recall = [0]*1250\n",
    "sum_rank = 0\n",
    "sum_class_rank = [0]*125\n",
    "count_recall_class = np.zeros((125,1250),np.float)\n",
    "i_coco =-1\n",
    "for i,img in enumerate(test_img_list):\n",
    "    imgname = img.split('/')[-1]\n",
    "    imgname = imgname.split('.jpg')[0]\n",
    "    imgcat = img.split('/')[0]\n",
    "    \n",
    "    sketch_list = os.listdir(sketch_paths+imgcat)\n",
    "    sketch_img_list = [skg for skg in sketch_list if skg.startswith(imgname+'-') and skg.endswith('-5.png')]#change this skg.endswith('-1.png') to the variation you want\n",
    "    \n",
    "    for sketch in sketch_img_list:\n",
    "        sketch_path = sketch_paths + imgcat+'/' + sketch\n",
    "        sketch_in = (transformer.preprocess('data', plt.imread(sketch_path)))\n",
    "        sketch_in = np.reshape([sketch_in],np.shape(sketch_net.blobs['data'].data))\n",
    "        %time query = sketch_net.forward(data=sketch_in)\n",
    "        query=np.copy(query[output_layer_sketch])\n",
    "        \n",
    "        %time distances, indices = nbrs.kneighbors(query.reshape(1, -1))\n",
    "        num_query = num_query+1\n",
    "        print('\\r','...'+sketch+'...')\n",
    "\n",
    "        print('knn results: ', indices[0])\n",
    "        for j,indice in enumerate(indices[0]):\n",
    "            if indice==i:\n",
    "                #this j is the right one.\n",
    "                count_recall[j] = count_recall[j]+1\n",
    "                print('\\r','ranking: '+imgcat+ ' '+sketch  + ' found at '  +str(j))\n",
    "                break\n",
    "                \n",
    "cum_count = [0]*1250\n",
    "sumc = 0\n",
    "for i,c in enumerate(count_recall):\n",
    "    sumc = sumc + c\n",
    "    cum_count[i] = sumc\n",
    "print('\\nRecall @K=1 = ', 1.00*cum_count[0]/cum_count[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
